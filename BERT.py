# -*- coding: utf-8 -*-
"""BERT IRONY AND HS, FINAL WORK

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18dPAu9icRSM_RgaJoRDsPBeAmPQJPcnn

**SE AVVII LA PARTE DI HS RIAVVIA LA SESSIONE PER AVVIARE LA PARTE DI IRONY!!!**\
"""

from google.colab import drive
drive.mount('/content/drive')

! pip install transformers datasets

from google.colab import files
uploaded = files.upload()

import zipfile
import os

#Percorso della cartella di destinazione in Google Drive
destination_path = "/content/drive/MyDrive/BERT"
os.makedirs(destination_path, exist_ok=True)

with zipfile.ZipFile("/content/drive/MyDrive/BERT-20250305T212545Z-001.zip", "r") as zip_ref:
    zip_ref.extractall(destination_path)

print(f"File estratti in: {destination_path}")

import os
import shutil

source_folder = "/content/drive/MyDrive/BERT/BERT"
destination_folder = "/content/drive/MyDrive/BERT"


if os.path.exists(source_folder):
    for item in os.listdir(source_folder):
        src_path = os.path.join(source_folder, item)
        dest_path = os.path.join(destination_folder, item)

        shutil.move(src_path, dest_path)

    #Dopo aver spostato tutto, elimina la cartella errata
    shutil.rmtree(source_folder)
    print(f"Cartella '{source_folder}' eliminata, ora tutto √® dentro '{destination_folder}'")
else:
    print(f"La cartella {source_folder} non esiste, nessuna operazione necessaria.")

from google.colab import drive
drive.mount('/content/drive')

"""Lettura e caricamento file"""

import pandas as pd
import os
cartella_training = "/content/drive/MyDrive/BERT/Dev_set"
cartella_test = "/content/drive/MyDrive/BERT/Test_set"

#Funzione per leggere solo i file .tsv in una cartella
def carica_tsv(cartella):
    dati = {}
    for file in os.listdir(cartella):
        if file.endswith(".tsv"):  # Controlla che il file sia .tsv
            file_path = os.path.join(cartella, file)
            df = pd.read_csv(file_path, sep='\t', encoding='utf-8')
            dati[file] = df
    return dati

#Caricamento dei dati
training_data = carica_tsv(cartella_training)
test_data = carica_tsv(cartella_test)
print("File training caricati:", list(training_data.keys()))
print("File test caricati:", list(test_data.keys()))

"""Distribuzione dataset di training"""

import pandas as pd

#Percorso del file TSV
file_path = "/content/drive/MyDrive/BERT/Dev_set/haspeede2_dev_taskAB_anon_revised.tsv"

#Carica il file con rilevamento automatico del separatore
df = pd.read_csv(file_path, sep=None, engine='python', encoding='utf-8')

print("Distribuzione label (hs):")
print(df['hs'].value_counts())

"""Distribuzione dataset di test"""

import pandas as pd

#Percorsi dei file da leggere
file_paths = [
    "/content/drive/MyDrive/BERT/Test_set/haspeede2_reference_taskAB-news_anon_revised.tsv",
    "/content/drive/MyDrive/BERT/Test_set/haspeede2_reference_taskAB-tweets_anon_revised.tsv"
]

#Carica e concatena i dataset
df_test = pd.concat([pd.read_csv(f, sep=',', encoding='utf-8') for f in file_paths], ignore_index=True)

#Mostra la distribuzione della colonna "hs"
print(df_test['hs'].value_counts())

"""Suddivisione del dataset. Abbiamo deciso 85% di training per dare pi√π spazio all'addestramento."""

import pandas as pd
from sklearn.model_selection import train_test_split
file_paths = [
    "/content/drive/MyDrive/BERT/Dev_set/haspeede2_dev_taskAB_anon_revised.tsv"
]

#Carica il dataset
df = pd.read_csv(file_paths[0], sep=',', encoding='utf-8')

#Pulizia colonne
df.columns = df.columns.str.strip()

#Suddivisione in train (85%) e validation (15%)
train_set, validation_set = train_test_split(df, test_size=0.15, random_state=2, stratify=df['hs'])

#Funzione per calcolare la distribuzione delle classi in percentuale
def count_classes_perc(data):
    return data['hs'].value_counts(normalize=True) * 100

#Calcolo statistiche
train_stats = count_classes_perc(train_set)
validation_stats = count_classes_perc(validation_set)
test_stats = count_classes_perc(df_test)

#Statistiche
print("Distribuzione delle classi in percentuale:\n")
print(f"Train Set:\n{train_stats}\n")
print(f"Validation Set:\n{validation_stats}\n")
print(f"Test Set:\n{test_stats}\n")
print(f"Train Set - Totale: {len(train_set)} | Classe 0: {train_stats[0]:.2f}% | Classe 1: {train_stats[1]:.2f}%")
print(f"Validation Set - Totale: {len(validation_set)} | Classe 0: {validation_stats[0]:.2f}% | Classe 1: {validation_stats[1]:.2f}%")
print(f"Test Set - Totale: {len(df_test)} | Classe 0: {test_stats[0]:.2f}% | Classe 1: {test_stats[1]:.2f}%")

"""Tokenizzazione e preparazione di BERT"""

!pip install transformers  # Se non √® gi√† installato
!pip install datasets
from transformers import AutoTokenizer
model_name = "dbmdz/bert-base-italian-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize_function(examples):
    return tokenizer(examples["full_text"], padding="max_length", truncation=True)

from datasets import Dataset as HFDataset

def preprocessing_data(data):
    df_temp = data[['full_text', 'hs']].copy()
    #Convertiamo 'hs' in colonna 'labels' per Hugging Face
    df_temp["labels"] = df_temp["hs"].astype(int)

    #Creaiamo un Dataset Hugging Face
    dataset = HFDataset.from_pandas(df_temp)
    tokenized_dt = dataset.map(tokenize_function, remove_columns=['full_text', 'hs'])
    return tokenized_dt.with_format("torch")

#Converte i 3 subset in dataset tokenizzati
train_dataset = preprocessing_data(train_set)
validation_dataset = preprocessing_data(validation_set)
test_dataset = preprocessing_data(df_test)

"""Classificazione di BERT 1;0"""

!pip install transformers

from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_name = "dbmdz/bert-base-italian-uncased"

model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=2  # 2 classi: hs=0 o 1
)

"""Configurazione del modello"""

#############################
#      TRAINING E PREDIZIONI HS      #
#############################

from google.colab import drive
drive.mount('/content/drive')

def set_seed(seed: int = 42):
    """Imposta il seed per la riproducibilit√†."""
    import random, numpy as np, torch
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

import logging
import os
import torch
import random
import numpy as np
from transformers import (
    Trainer,
    TrainingArguments,
    EarlyStoppingCallback,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainerCallback
)
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EpochLogger(TrainerCallback):
    def on_epoch_end(self, args, state, control, **kwargs):
        last_log = state.log_history[-1] if state.log_history else {}
        logger.info(f"Epoch {state.epoch:.2f} completata. Log: {last_log}")
        return control

def main_hs():
    drive.mount('/content/drive')

    set_seed(42)

    model_dir = "/content/drive/MyDrive/BERT/ModelloHS"
    os.makedirs(model_dir, exist_ok=True)
    checkpoint_path = os.path.join(model_dir, "bert_hs_checkpoint.pt")

    model = AutoModelForSequenceClassification.from_pretrained(
        "dbmdz/bert-base-italian-uncased",
        num_labels=2,
        hidden_dropout_prob=0.3,
        attention_probs_dropout_prob=0.3,
    )

    #Funzione di metriche per HS
    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=1)
        return {
            "accuracy": accuracy_score(labels, preds),
            "precision": precision_score(labels, preds),
            "recall": recall_score(labels, preds),
            "f1": f1_score(labels, preds)
        }

    training_args = TrainingArguments(
        output_dir="/results",
        learning_rate=2e-5,
        per_device_train_batch_size=32,
        per_device_eval_batch_size=32,
        gradient_accumulation_steps=1,
        fp16=True,
        lr_scheduler_type="linear",
        warmup_ratio=0.1,
        num_train_epochs=18,
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        report_to="none",
        optim="adamw_torch",
        adam_beta1=0.9,
        adam_beta2=0.98,
        weight_decay=0.01,
        save_total_limit=2,
        dataloader_num_workers=2,
        logging_dir="./logs",
        max_grad_norm=1.0
    )

    global tokenizer, train_dataset, validation_dataset
    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

    trainer_hs = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=validation_dataset,
        compute_metrics=compute_metrics,
        data_collator=data_collator,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=10), EpochLogger()]
    )

    if os.path.exists(checkpoint_path):
        logger.info(f"Caricamento pesi da {checkpoint_path}...")
        state_dict = torch.load(checkpoint_path, map_location=torch.device("cpu"))
        model.load_state_dict(state_dict, strict=False)
        logger.info("Checkpoint caricato. Riprendo l'addestramento per HS...")
        trainer_hs.train(resume_from_checkpoint=checkpoint_path)
    else:
        logger.info("Nessun checkpoint trovato. Avvio training da zero per HS...")
        trainer_hs.train()

    torch.save(model.state_dict(), checkpoint_path)
    logger.info(f"Modello HS salvato in {checkpoint_path}")
    logger.info("Storico dei log durante il training:")
    logger.info(trainer_hs.state.log_history)

    return trainer_hs

if __name__ == "__main__":
    trainer_hs = main_hs()

#########################################
#   PREDIZIONI SUL FILE "post_accordo_totale_unici_converted.csv"
#########################################

# Carica il file di analisi (con 21 frasi)
df_accordo = pd.read_csv("/content/drive/MyDrive/BERT/Analisi/post_accordo_totale_unici_converted.csv", encoding="utf-8")
print("Colonne del file di accordo totale unici:", df_accordo.columns.tolist())

df_temp = df_accordo[["text", "hs"]].copy()
df_temp["labels"] = df_temp["hs"].astype(int)
dataset_accordo = HFDataset.from_pandas(df_temp)

def tokenize_accordo(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

dataset_accordo = dataset_accordo.map(tokenize_accordo, batched=True, remove_columns=["text", "hs"])
dataset_accordo.set_format("torch")

#Effettua le predizioni con il modello HS (trainer_hs)
predictions_hs = trainer_hs.predict(dataset_accordo)
hs_pred = np.argmax(predictions_hs.predictions, axis=1)

#Aggiungi la colonna "hs_pred" al DataFrame
df_accordo["hs_pred"] = hs_pred
print("Predizioni HS sul file di accordo totale unici:")
print(df_accordo[["text", "hs", "hs_pred"]])

#########################################
#   SEZIONE DI ESTRAZIONE DEGLI ERRORI
#########################################
# Estrae fino a 5 messaggi in cui il modello HS ha sbagliato la predizione.
mask = df_accordo["hs_pred"] != df_accordo["hs"]
df_errors = df_accordo[mask].head(5)

def generate_comment(row):
    comment = ""
    if row["hs_pred"] != row["hs"]:
        comment += "Errore HS: possibile linguaggio ambiguo o mal interpretato."
    return comment

df_errors["comment"] = df_errors.apply(generate_comment, axis=1)

print("\n--- Messaggi in cui il modello HS ha sbagliato (max. 5) ---")
for idx, row in df_errors.iterrows():
    print("\nMessaggio:", row["text"])
    print("HS -> Vero:", row["hs"], "| Predetto:", row["hs_pred"])
    print("Commento:", row["comment"])

"""Metriche del modello"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report

def plot_confusion_matrix(true_labels, pred_labels, task="HS"):
    #Seleziona le classi in base al task (HS o Irony)
    if task.lower() == "hs":
        class_names = ["No HS", "HS"]
    elif task.lower() == "irony":
        class_names = ["No Irony", "Irony"]
    else:
        class_names = ["Class 0", "Class 1"]

    #Calcola la confusion matrix
    cm = confusion_matrix(true_labels, pred_labels)

    #Stampa il classification report
    print("=== CLASSIFICATION REPORT ===\n")
    print(classification_report(true_labels, pred_labels, target_names=class_names))

    #Stampa la confusion matrix in formato numerico
    print("=== CONFUSION MATRIX (valori assoluti) ===\n", cm, "\n")

    #Creazione della figura
    fig, ax = plt.subplots(figsize=(6, 6))
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    #Stampa i valori all'interno delle celle
    for (i, j), value in np.ndenumerate(cm):
        ax.text(j, i, str(value), ha="center", va="center", color="black", fontsize=12)

    #Imposta tick ed etichette sugli assi
    ax.set_xticks(range(len(class_names)))
    ax.set_yticks(range(len(class_names)))
    ax.set_xticklabels(class_names, fontsize=12)
    ax.set_yticklabels(class_names, fontsize=12)

    #Titolo e label degli assi
    plt.title("MATRICE DI CONFUSIONE", fontsize=14, pad=20)
    plt.xlabel("Predetto", fontsize=12)
    plt.ylabel("Reale", fontsize=12)

    plt.show()

#ESEMPIO DI UTILIZZO:
#Si assume che l'oggetto 'trainer' e il dataset 'test_dataset' siano gi√† stati definiti
#nel contesto del file "bert_irony_and_hs,_final_work.py".
predictions = trainer_hs.predict(test_dataset)
predicted_labels = np.argmax(predictions.predictions, axis=1)
true_labels = predictions.label_ids

#Per il task Hate Speech (HS):
plot_confusion_matrix(true_labels, predicted_labels, task="HS")

"""Adesso procediamo con Irony, **MI RACCOMANDO NON AVVIARE IRONY SENZA AVER RIAVVIATO LA SESSIONE ALTRIMENTI VA IN CONFLITTO**"""

import pandas as pd
import os
cartella_training = "/content/drive/MyDrive/BERT/Ironita/Training"
cartella_test = "/content/drive/MyDrive/BERT/Ironita/Test"

#Funzione per leggere solo i file .tsv in una cartella
def carica_tsv(cartella):
    dati = {}
    for file in os.listdir(cartella):
        if file.endswith(".csv"):  # Controlla che il file sia .csv
            file_path = os.path.join(cartella, file)
            df = pd.read_csv(file_path, sep='\t', encoding='utf-8')
            dati[file] = df
    return dati

#Caricamento dei dati
training_data = carica_tsv(cartella_training)
test_data = carica_tsv(cartella_test)
print("File training caricati:", list(training_data.keys()))
print("File test caricati:", list(test_data.keys()))

"""Distribuzione dataset di training"""

import pandas as pd

#Percorso del file TSV
file_path = "/content/drive/MyDrive/BERT/Ironita/Training/training_ironita2018_anon_REV_.csv"

#Carica il file con rilevamento automatico del separatore
df = pd.read_csv(file_path, sep=None, engine='python', encoding='utf-8')

print("Distribuzione label (irony):")
print(df['irony'].value_counts())

"""Distribuzione dataset di test"""

import pandas as pd

file_path = "/content/drive/MyDrive/BERT/Ironita/Test/test_gold_ironita2018_anon_REV_.csv"

df_test = pd.read_csv(file_path, sep=None, engine='python', encoding='utf-8')

#Mostra le colonne presenti nel file
print("Colonne nel dataset:", df_test.columns.tolist())

print("\nDistribuzione della colonna 'irony':")
print(df_test['irony'].value_counts(dropna=False))

"""Bilanciamento dataset Irony"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Percorso gi√† gestito, quindi utilizziamo direttamente df_test

# Percorso del dataset di training (gi√† presente in precedenza)
file_path = "/content/drive/MyDrive/BERT/Ironita/Training/training_ironita2018_anon_REV_.csv"

# Carica il dataset di training
df = pd.read_csv(file_path, sep=';', encoding='utf-8', on_bad_lines='skip')

# Pulizia colonne
df.columns = df.columns.str.strip()
df_test.columns = df_test.columns.str.strip()

# Suddivisione in train (85%) e validation (15%)
train_set, validation_set = train_test_split(df, test_size=0.15, random_state=2, stratify=df['irony'])

# Funzione per calcolare la distribuzione delle classi in percentuale
def count_classes_perc(data):
    return data['irony'].value_counts(normalize=True) * 100

# Calcolo statistiche per train, validation e test
train_stats = count_classes_perc(train_set)
validation_stats = count_classes_perc(validation_set)
test_stats = count_classes_perc(df_test)

# Mostra le statistiche
print("Distribuzione delle classi in percentuale:\n")
print(f"Train Set - Totale: {len(train_set)} | Classe 0: {train_stats[0]:.2f}% | Classe 1: {train_stats[1]:.2f}%")
print(f"Validation Set - Totale: {len(validation_set)} | Classe 0: {validation_stats[0]:.2f}% | Classe 1: {validation_stats[1]:.2f}%")
print(f"Test Set - Totale: {len(df_test)} | Classe 0: {test_stats[0]:.2f}% | Classe 1: {test_stats[1]:.2f}%")

# Mostra le prime righe dei dataset elaborati
print("\nEsempio Train Set:")
print(train_set.head())

print("\nEsempio Validation Set:")
print(validation_set.head())

print("\nEsempio Test Set:")
print(df_test.head())

!pip install transformers
!pip install datasets
from transformers import AutoTokenizer
from datasets import Dataset as HFDataset

model_name = "dbmdz/bert-base-italian-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def preprocessing_data(data):
    # Determina quale colonna contiene il testo
    if "full_text" in data.columns:
        text_col = "full_text"
    elif "text" in data.columns:
        text_col = "text"
    else:
        raise ValueError("Nessuna colonna contenente il testo trovata nel DataFrame.")

    #Seleziona la colonna del testo e 'irony'
    df_temp = data[[text_col, "irony"]].copy()
    #Converte 'irony' in una colonna 'labels' per Hugging Face
    df_temp["labels"] = df_temp["irony"].astype(int)

    #Crea un Dataset Hugging Face dal DataFrame
    dataset = HFDataset.from_pandas(df_temp)

    #Tokenizza i dati utilizzando una funzione lambda che usa la variabile locale 'text_col'
    tokenized_dt = dataset.map(
        lambda examples: tokenizer(examples[text_col], padding="max_length", truncation=True),
        remove_columns=[text_col, "irony"]
    )
    return tokenized_dt.with_format("torch")

train_dataset = preprocessing_data(train_set)
validation_dataset = preprocessing_data(validation_set)
test_dataset = preprocessing_data(df_test)

!pip install transformers

from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_name = "dbmdz/bert-base-italian-uncased"

model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=2  # 2 classi: irony=0 o 1
)

#############################
#      TRAINING E TEST IRONY      #
#############################

from google.colab import drive
import logging
import os
import torch
import numpy as np
import pandas as pd
from transformers import (
    Trainer,
    TrainingArguments,
    EarlyStoppingCallback,
    AutoModelForSequenceClassification,
    AutoTokenizer,
    DataCollatorWithPadding,
    TrainerCallback
)
from datasets import Dataset as HFDataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

# **Monta Google Drive**
drive.mount('/content/drive')

# **Configurazione logging**
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# **Imposta il seed per la riproducibilit√†**
def set_seed(seed: int = 42):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

# **Classe per loggare alla fine di ogni epoca**
class EpochLogger(TrainerCallback):
    def on_epoch_end(self, args, state, control, **kwargs):
        last_log = state.log_history[-1] if state.log_history else {}
        logger.info(f"Epoch {state.epoch:.2f} completata. Log: {last_log}")
        return control

# **üîπ Caricamento e divisione dataset di training**
file_path = "/content/drive/MyDrive/BERT/Ironita/Training/training_ironita2018_anon_REV_.csv"

df = pd.read_csv(file_path, sep=None, engine='python', encoding='utf-8', on_bad_lines='skip')
df.columns = df.columns.str.strip()

# Divisione train-validation stratificata
train_set, validation_set = train_test_split(df, test_size=0.15, random_state=2, stratify=df['irony'])

# **üîπ Training del modello**
def train_irony_model():
    set_seed(42)

    model_dir = "/content/drive/MyDrive/BERT/ModelloIrony"
    os.makedirs(model_dir, exist_ok=True)
    checkpoint_path = os.path.join(model_dir, "bert_irony_checkpoint.pt")

    model_name = "dbmdz/bert-base-italian-uncased"
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # **Tokenizzazione e creazione dataset Hugging Face**
    def tokenize_function(examples):
        return tokenizer(examples["text"], padding="max_length", truncation=True)

    # Prepara i dataset
    for dataset in [train_set, validation_set]:
        dataset["labels"] = dataset["irony"].astype(int)

    train_dataset = HFDataset.from_pandas(train_set).remove_columns(["irony"])
    validation_dataset = HFDataset.from_pandas(validation_set).remove_columns(["irony"])

    train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=["text"])
    validation_dataset = validation_dataset.map(tokenize_function, batched=True, remove_columns=["text"])

    train_dataset.set_format("torch")
    validation_dataset.set_format("torch")

    # **Creazione del modello con dropout ridotto**
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=2,
        hidden_dropout_prob=0.2,  # Modifica: ridotto da 0.3 a 0.2
        attention_probs_dropout_prob=0.2,  # Modifica: ridotto da 0.3 a 0.2
    )

    # **Funzione di metriche per IRONY**
    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=1)
        return {
            "accuracy": accuracy_score(labels, preds),
            "precision": precision_score(labels, preds),
            "recall": recall_score(labels, preds),
            "f1": f1_score(labels, preds)
        }

    # **TrainingArguments con le modifiche essenziali**
    training_args = TrainingArguments(
        output_dir="/results",
        logging_strategy="epoch",
        logging_steps=10,
        log_level="info",
        report_to="none",
        learning_rate=1e-5,  # Modifica: ridotto da 2e-5 a 1e-5
        per_device_train_batch_size=32,
        per_device_eval_batch_size=32,
        num_train_epochs=15,  # Modifica: aumentato da 10 a 15
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        optim="adamw_torch",
        fp16=True,  # Usa Mixed Precision Training per accelerare
        save_total_limit=2,
        dataloader_num_workers=2,
        logging_dir="./logs",
        lr_scheduler_type="linear",  # Modifica: aggiunto scheduler
    )

    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

    trainer_irony = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=validation_dataset,
        compute_metrics=compute_metrics,
        data_collator=data_collator,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=10), EpochLogger()]
    )

    if os.path.exists(checkpoint_path):
        logger.info(f"Caricamento pesi da {checkpoint_path}...")
        state_dict = torch.load(checkpoint_path, map_location=torch.device("cpu"))
        model.load_state_dict(state_dict, strict=False)
        trainer_irony.train(resume_from_checkpoint=checkpoint_path)
    else:
        trainer_irony.train()

    torch.save(model.state_dict(), checkpoint_path)
    return trainer_irony, tokenizer

# **Avvia il training**
trainer_irony, tokenizer = train_irony_model()

#########################################
#   TEST SULLE 21 FRASI
#########################################

df_21 = pd.read_csv("/content/drive/MyDrive/BERT/Analisi/post_accordo_totale_unici_converted.csv", encoding="utf-8")

df_21["labels"] = df_21["irony"].astype(int)
dataset_21 = HFDataset.from_pandas(df_21)

def tokenize_21(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

dataset_21 = dataset_21.map(tokenize_21, batched=True, remove_columns=["text", "irony"])
dataset_21.set_format("torch")

# **Effettua le predizioni sulle 21 frasi**
predictions_irony = trainer_irony.predict(dataset_21)
df_21["irony_pred"] = np.argmax(predictions_irony.predictions, axis=1)

# **üîç STAMPA LE 21 FRASI CON PREDIZIONI**
print("\nüîç Tutte le 21 frasi con le predizioni IRONY:")
print(df_21[["text", "irony", "irony_pred"]].to_string(index=False))

# **üîπ Analisi dei risultati**
print("\n=== CLASSIFICATION REPORT ===\n")
print(classification_report(df_21["irony"], df_21["irony_pred"], target_names=["No Irony", "Irony"]))

cm = confusion_matrix(df_21["irony"], df_21["irony_pred"])
print("\n=== CONFUSION MATRIX ===\n", cm, "\n")

fig, ax = plt.subplots(figsize=(6,6))
cax = ax.matshow(cm, cmap=plt.cm.Blues)
fig.colorbar(cax)

for (i, j), value in np.ndenumerate(cm):
    ax.text(j, i, str(value), ha='center', va='center', color='black', fontsize=12)

ax.set_xticks([0, 1])
ax.set_yticks([0, 1])
ax.set_xticklabels(["No Irony", "Irony"], fontsize=12)
ax.set_yticklabels(["No Irony", "Irony"], fontsize=12)

plt.xlabel("Predetto", fontsize=12)
plt.ylabel("Reale", fontsize=12)
plt.title("MATRICE DI CONFUSIONE", fontsize=14)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report

def plot_confusion_matrix(true_labels, pred_labels, class_names=["No Irony", "Irony"]):
    cm = confusion_matrix(true_labels, pred_labels)

    print("=== CLASSIFICATION REPORT ===\n")
    print(classification_report(true_labels, pred_labels, target_names=class_names))

    print("=== CONFUSION MATRIX (valori assoluti) ===\n", cm, "\n")

    fig, ax = plt.subplots(figsize=(6, 6))
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    for (i, j), value in np.ndenumerate(cm):
        ax.text(j, i, str(value), ha='center', va='center', color='black', fontsize=12)

    ax.set_xticks(range(len(class_names)))
    ax.set_yticks(range(len(class_names)))
    ax.set_xticklabels(class_names, fontsize=12)
    ax.set_yticklabels(class_names, fontsize=12)

    plt.title("MATRICE DI CONFUSIONE", fontsize=14, pad=20)
    plt.xlabel("Predetto", fontsize=12)
    plt.ylabel("Reale", fontsize=12)

    plt.show()


predictions = trainer_irony.predict(test_dataset) #qui dobbiamo modificare ancora il codice per l'ultimo task
predicted_labels = np.argmax(predictions.predictions, axis=1)
true_labels = predictions.label_ids

plot_confusion_matrix(true_labels, predicted_labels, class_names=["No Irony", "Irony"])

"""**AVVIARE SOLTANTO SE SI E' RUNNATO TUTTA LA PARTE DI IRONY**"""

import pandas as pd
import numpy as np
import torch
from transformers import Trainer, AutoTokenizer
from datasets import Dataset as HFDataset
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

model_name = "dbmdz/bert-base-italian-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

def carica_dataset_annotazioni(path, sep=",", colonna_ironia="irony"):
    df = pd.read_csv(path, sep=sep, encoding='utf-8')
    df = df.rename(columns=lambda x: x.strip())

    if colonna_ironia not in df.columns:
        raise ValueError(f"La colonna '{colonna_ironia}' non √® presente nel dataset. Colonne disponibili: {df.columns}")

    # Normalizza i valori di ironia (es. "yes"/"no" ‚Üí 1/0)
    df[colonna_ironia] = df[colonna_ironia].replace({'yes': 1, 'no': 0}).astype(int)

    # Determina quale colonna contiene il testo
    text_col = "full_text" if "full_text" in df.columns else "text"

    return df, text_col

dataset_path = "/content/drive/MyDrive/BERT/Analisi/annotazioni_di_tuttu_BERT_preprocessed.csv"

df_ironia, text_col = carica_dataset_annotazioni(dataset_path, sep=",")

def preprocessing_data(data, text_col):
    df_temp = data[[text_col, "irony"]].copy()
    df_temp["labels"] = df_temp["irony"].astype(int)

    dataset = HFDataset.from_pandas(df_temp)

    tokenized_dt = dataset.map(
        lambda examples: tokenizer(examples[text_col], padding="max_length", truncation=True),
        remove_columns=[text_col, "irony"]
    )
    return tokenized_dt.with_format("torch")

tokenized_ironia = preprocessing_data(df_ironia, text_col)

#Effettua le predizioni con BERT sul dataset annotato, (QUI MANCA IL CODICE CORRETTO PER L'ULTIMO TASK)
predictions = trainer_irony.predict(tokenized_ironia)
predictions_labels = np.argmax(predictions.predictions, axis=1)


def analisi_annotazioni(pred_labels, true_labels):
    print("\n=== CLASSIFICATION REPORT ===\n")
    print(classification_report(true_labels, pred_labels, target_names=["No Ironia", "Ironia"]))

    cm = confusion_matrix(true_labels, pred_labels)
    print("\n=== CONFUSION MATRIX ===\n", cm, "\n")

    #Plot della matrice di confusione
    fig, ax = plt.subplots(figsize=(6,6))
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    for (i, j), value in np.ndenumerate(cm):
        ax.text(j, i, str(value), ha='center', va='center', color='black', fontsize=12)

    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["No Ironia", "Ironia"], fontsize=12)
    ax.set_yticklabels(["No Ironia", "Ironia"], fontsize=12)

    plt.xlabel("Predetto", fontsize=12)
    plt.ylabel("Reale", fontsize=12)
    plt.title("MATRICE DI CONFUSIONE", fontsize=14)
    plt.show()

print("Analisi comparativa tra BERT e annotazioni totali:")
analisi_annotazioni(predictions_labels, df_ironia["irony"])

"""**AVVIARE SOLTANTO SE SI E' RUNNATO LA PARTE DI HATE SPEECH**"""

import pandas as pd
import numpy as np
import torch
from transformers import Trainer, AutoTokenizer
from datasets import Dataset as HFDataset
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

model_name = "dbmdz/bert-base-italian-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

def carica_dataset_annotazioni(path, sep=",", colonna_hs="hs"):
    df = pd.read_csv(path, sep=sep, encoding='utf-8')
    df = df.rename(columns=lambda x: x.strip())

    if colonna_hs not in df.columns:
        raise ValueError(f"La colonna '{colonna_hs}' non √® presente nel dataset. Colonne disponibili: {df.columns}")

    df[colonna_hs] = df[colonna_hs].replace({'yes': 1, 'no': 0}).astype(int)

    text_col = "full_text" if "full_text" in df.columns else "text"

    return df, text_col

dataset_path_hs = "/content/drive/MyDrive/BERT/Analisi/annotazioni_di_tuttu_BERT.csv"
dataset_path_commenti = "/content/drive/MyDrive/BERT/Analisi/commenti_uniti.csv"

df_hs, text_col = carica_dataset_annotazioni(dataset_path_hs, sep=",", colonna_hs="hs")
df_commenti, text_col_commenti = carica_dataset_annotazioni(dataset_path_commenti, sep=",", colonna_hs="hs")

def preprocessing_data(data, text_col):
    df_temp = data[[text_col, "hs"].copy()]
    df_temp["labels"] = df_temp["hs"].astype(int)

    dataset = HFDataset.from_pandas(df_temp)

    tokenized_dt = dataset.map(
        lambda examples: tokenizer(examples[text_col], padding="max_length", truncation=True),
        remove_columns=[text_col, "hs"]
    )
    return tokenized_dt.with_format("torch")

tokenized_hs = preprocessing_data(df_hs, text_col)
tokenized_commenti = preprocessing_data(df_commenti, text_col_commenti)

# Effettua le predizioni con BERT sul dataset annotato per HS
predictions_hs = trainer_hs.predict(tokenized_hs)
predictions_labels_hs = np.argmax(predictions_hs.predictions, axis=1)

predictions_commenti = trainer_hs.predict(tokenized_commenti)
predictions_labels_commenti = np.argmax(predictions_commenti.predictions, axis=1)

def analisi_annotazioni(pred_labels, true_labels):
    print("\n=== CLASSIFICATION REPORT ===\n")
    print(classification_report(true_labels, pred_labels, target_names=["No HS", "HS"]))

    cm = confusion_matrix(true_labels, pred_labels)
    print("\n=== CONFUSION MATRIX ===\n", cm, "\n")

    # Plot della matrice di confusione
    fig, ax = plt.subplots(figsize=(6,6))
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    for (i, j), value in np.ndenumerate(cm):
        ax.text(j, i, str(value), ha='center', va='center', color='black', fontsize=12)

    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["No HS", "HS"], fontsize=12)
    ax.set_yticklabels(["No HS", "HS"], fontsize=12)

    plt.xlabel("Predetto", fontsize=12)
    plt.ylabel("Reale", fontsize=12)
    plt.title("MATRICE DI CONFUSIONE", fontsize=14)
    plt.show()

print("Analisi comparativa tra BERT e annotazioni totali per Hate Speech:")
analisi_annotazioni(predictions_labels_hs, df_hs["hs"])

print("Analisi comparativa tra BERT e commenti uniti per Hate Speech:")
analisi_annotazioni(predictions_labels_commenti, df_commenti["hs"])

"""DA QUI IN POI E' DA REVISIONARE PER L'ULTIMA TASK"""

import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer
from datasets import Dataset as HFDataset
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Inizializza il tokenizer
model_name = "dbmdz/bert-base-italian-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Funzione di tokenizzazione
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

# Funzione per caricare e processare il dataset
def carica_dataset_annotazioni(path, sep=",", colonna_hs="hs"):
    df = pd.read_csv(path, sep=sep, encoding='utf-8')
    df = df.rename(columns=lambda x: x.strip())  # Rimuove spazi nei nomi delle colonne

    if colonna_hs not in df.columns:
        raise ValueError(f"La colonna '{colonna_hs}' non √® presente nel dataset. Colonne disponibili: {df.columns}")

    df[colonna_hs] = df[colonna_hs].replace({'yes': 1, 'no': 0}).astype(int)
    text_col = "full_text" if "full_text" in df.columns else "text"

    return df, text_col

# Funzione per la tokenizzazione e preparazione del dataset
def preprocessing_data(data, text_col):
    df_temp = data[[text_col, "hs"]].copy()
    df_temp["labels"] = df_temp["hs"].astype(int)

    dataset = HFDataset.from_pandas(df_temp)

    tokenized_dt = dataset.map(
        lambda examples: tokenizer(examples[text_col], padding="max_length", truncation=True),
        remove_columns=[text_col, "hs"]
    )
    return tokenized_dt.with_format("torch")

# Funzione per analizzare le prestazioni
def analisi_annotazioni(pred_labels, true_labels):
    print("\n=== CLASSIFICATION REPORT ===\n")
    print(classification_report(true_labels, pred_labels, target_names=["No HS", "HS"]))

    cm = confusion_matrix(true_labels, pred_labels)
    print("\n=== CONFUSION MATRIX ===\n", cm, "\n")

    fig, ax = plt.subplots(figsize=(6,6))
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    for (i, j), value in np.ndenumerate(cm):
        ax.text(j, i, str(value), ha='center', va='center', color='black', fontsize=12)

    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["No HS", "HS"], fontsize=12)
    ax.set_yticklabels(["No HS", "HS"], fontsize=12)

    plt.xlabel("Predetto", fontsize=12)
    plt.ylabel("Reale", fontsize=12)
    plt.title("MATRICE DI CONFUSIONE", fontsize=14)
    plt.show()

# Percorsi dei nuovi dataset
dataset_paths = {
    "No Social": "/content/drive/MyDrive/BERT/Analisi/annotazioni_di_no_social_BERT_preprocessed_colonna_hs.csv",
    "Social": "/content/drive/MyDrive/BERT/Analisi/annotazioni_di_social_BERT_preprocessed_colonna_hs.csv"
}

# Elaborazione e analisi dei dataset
for dataset_name, dataset_path in dataset_paths.items():
    print(f"\n--- Analisi per il dataset: {dataset_name} ---")

    df_hs, text_col = carica_dataset_annotazioni(dataset_path, sep=",", colonna_hs="hs")
    tokenized_hs = preprocessing_data(df_hs, text_col)

    predictions_hs = trainer_hs.predict(tokenized_hs)
    predictions_labels_hs = np.argmax(predictions_hs.predictions, axis=1)

    analisi_annotazioni(predictions_labels_hs, df_hs["hs"])

"""MATRICE DI CONFUSIONE DEI 21 COMMENTI SU HS"""

import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer
from datasets import Dataset as HFDataset
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Inizializza il tokenizer
model_name = "dbmdz/bert-base-italian-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Funzione di tokenizzazione
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

# Funzione per caricare e processare il dataset
def carica_dataset_annotazioni(path, sep=",", colonna_hs="hs"):
    df = pd.read_csv(path, sep=sep, encoding='utf-8')
    df = df.rename(columns=lambda x: x.strip())  # Rimuove spazi nei nomi delle colonne

    if colonna_hs not in df.columns:
        raise ValueError(f"La colonna '{colonna_hs}' non √® presente nel dataset. Colonne disponibili: {df.columns}")

    df[colonna_hs] = df[colonna_hs].replace({'yes': 1, 'no': 0}).astype(int)
    text_col = "full_text" if "full_text" in df.columns else "text"

    return df, text_col

# Funzione per la tokenizzazione e preparazione del dataset
def preprocessing_data(data, text_col):
    df_temp = data[[text_col, "hs"]].copy()
    df_temp["labels"] = df_temp["hs"].astype(int)

    dataset = HFDataset.from_pandas(df_temp)

    tokenized_dt = dataset.map(
        lambda examples: tokenizer(examples[text_col], padding="max_length", truncation=True),
        remove_columns=[text_col, "hs"]
    )
    return tokenized_dt.with_format("torch")

# Funzione per analizzare le prestazioni
def analisi_annotazioni(pred_labels, true_labels):
    print("\n=== CLASSIFICATION REPORT ===\n")
    print(classification_report(true_labels, pred_labels, target_names=["No HS", "HS"]))

    cm = confusion_matrix(true_labels, pred_labels)
    print("\n=== CONFUSION MATRIX ===\n", cm, "\n")

    fig, ax = plt.subplots(figsize=(6,6))
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    for (i, j), value in np.ndenumerate(cm):
        ax.text(j, i, str(value), ha='center', va='center', color='black', fontsize=12)

    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["No HS", "HS"], fontsize=12)
    ax.set_yticklabels(["No HS", "HS"], fontsize=12)

    plt.xlabel("Predetto", fontsize=12)
    plt.ylabel("Reale", fontsize=12)
    plt.title("MATRICE DI CONFUSIONE", fontsize=14)
    plt.show()

# Percorsi dei dataset
dataset_paths = {
    "No Social": "/content/drive/MyDrive/BERT/Analisi/annotazioni_di_no_social_BERT_preprocessed_colonna_hs.csv",
    "Social": "/content/drive/MyDrive/BERT/Analisi/annotazioni_di_social_BERT_preprocessed_colonna_hs.csv",
    "Post Accordo Totale Unici": "/content/drive/MyDrive/BERT/Analisi/post_accordo_totale_unici_converted.csv"
}

# Elaborazione e analisi dei dataset
for dataset_name, dataset_path in dataset_paths.items():
    print(f"\n--- Analisi per il dataset: {dataset_name} ---")

    df_hs, text_col = carica_dataset_annotazioni(dataset_path, sep=",", colonna_hs="hs")
    tokenized_hs = preprocessing_data(df_hs, text_col)

    predictions_hs = trainer_hs.predict(tokenized_hs)
    predictions_labels_hs = np.argmax(predictions_hs.predictions, axis=1)

    analisi_annotazioni(predictions_labels_hs, df_hs["hs"])

import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer
from datasets import Dataset as HFDataset
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Inizializza il tokenizer
model_name = "dbmdz/bert-base-italian-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Funzione di tokenizzazione
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

# Funzione per caricare e processare il dataset
def carica_dataset_annotazioni(path, sep=",", colonna_irony="irony"):
    df = pd.read_csv(path, sep=sep, encoding='utf-8')
    df = df.rename(columns=lambda x: x.strip())  # Rimuove spazi nei nomi delle colonne

    if colonna_irony not in df.columns:
        raise ValueError(f"La colonna '{colonna_irony}' non √® presente nel dataset. Colonne disponibili: {df.columns}")

    df[colonna_irony] = df[colonna_irony].replace({'yes': 1, 'no': 0}).astype(int)
    text_col = "full_text" if "full_text" in df.columns else "text"

    return df, text_col

# Funzione per la tokenizzazione e preparazione del dataset
def preprocessing_data(data, text_col):
    df_temp = data[[text_col, "irony"]].copy()
    df_temp["labels"] = df_temp["irony"].astype(int)

    dataset = HFDataset.from_pandas(df_temp)

    tokenized_dt = dataset.map(
        lambda examples: tokenizer(examples[text_col], padding="max_length", truncation=True),
        remove_columns=[text_col, "irony"]
    )
    return tokenized_dt.with_format("torch")

# Funzione per analizzare le prestazioni
def analisi_annotazioni(pred_labels, true_labels):
    print("\n=== CLASSIFICATION REPORT ===\n")
    print(classification_report(true_labels, pred_labels, target_names=["No Irony", "Irony"]))

    cm = confusion_matrix(true_labels, pred_labels)
    print("\n=== CONFUSION MATRIX ===\n", cm, "\n")

    fig, ax = plt.subplots(figsize=(6,6))
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    for (i, j), value in np.ndenumerate(cm):
        ax.text(j, i, str(value), ha='center', va='center', color='black', fontsize=12)

    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["No Irony", "Irony"], fontsize=12)
    ax.set_yticklabels(["No Irony", "Irony"], fontsize=12)

    plt.xlabel("Predetto", fontsize=12)
    plt.ylabel("Reale", fontsize=12)
    plt.title("MATRICE DI CONFUSIONE", fontsize=14)
    plt.show()

# Percorsi dei dataset
dataset_paths = {
    "No Social": "/content/drive/MyDrive/BERT/Analisi/annotazioni_di_no_social_BERT_preprocessed_colonna_irony.csv",
    "Social": "/content/drive/MyDrive/BERT/Analisi/annotazioni_di_social_BERT_preprocessed_colonna_irony.csv",
    "Post Accordo Totale Unici": "/content/drive/MyDrive/BERT/Analisi/post_accordo_totale_unici_converted.csv"
}

# Elaborazione e analisi dei dataset
for dataset_name, dataset_path in dataset_paths.items():
    print(f"\n--- Analisi per il dataset: {dataset_name} ---")

    df_irony, text_col = carica_dataset_annotazioni(dataset_path, sep=",", colonna_irony="irony")
    tokenized_irony = preprocessing_data(df_irony, text_col)

    predictions_irony = trainer_irony.predict(tokenized_irony)
    predictions_labels_irony = np.argmax(predictions_irony.predictions, axis=1)

    analisi_annotazioni(predictions_labels_irony, df_irony["irony"])